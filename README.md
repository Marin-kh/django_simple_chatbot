# سامانه هوشمند پرسش از اسناد

این پروژه یک سامانه پیشرفته پرسش و پاسخ بر پایه اسناد متنی است که با استفاده از تکنیک **Retrieval-Augmented Generation (RAG)** پیاده‌سازی شده است.  
کاربر می‌تواند اسناد متنی خود را در سیستم ثبت کند و سپس به زبان طبیعی (فارسی) از محتوای آن‌ها سوال بپرسد.  
سیستم به‌طور هوشمند بخش‌های مرتبط را از اسناد بازیابی کرده و با کمک مدل زبانی قدرتمند، پاسخ دقیق و مبتنی بر سند تولید می‌کند.

---

## ویژگی‌های کلیدی

- پشتیبانی کامل از زبان فارسی  
- تقسیم هوشمند اسناد طولانی به تیکه‌های معنادار  
- جستجوی معنایی با استفاده از Embedding مدل چندزبانه  
- تولید پاسخ با مدل زبانی Llama 3.1 (از طریق Groq API)  
- پنل مدیریت برای ثبت و مدیریت اسناد  
- رابط کاربری ساده برای پرسش های مرتبط با اسناد  
- ذخیره خودکار تاریخچه پرسش‌ها و پاسخ‌ها  
- پشتیبانی از Docker برای استقرار آسان  

---

## معماری سیستم

- **بک‌اند**: Django 5.0  
- **Vector Store**: InMemoryVectorStore (یا Chroma برای ذخیره دائمی)  
- **Embedding Model**: `intfloat/multilingual-e5-large` (پشتیبانی عالی از فارسی)  
- **Text Splitter**: RecursiveCharacterTextSplitter با تنظیمات بهینه برای فارسی  
- **LLM**: Llama 3.1 8B (از طریق Groq API)  
- **فرانت‌اند**: Tailwind CSS + HTML  

---

## پیش‌نیازها

- Python 3.12  
- Docker و Docker Compose (برای اجرای کانتینری)  
- کلید API از Groq (برای مدل زبانی)  

---

## نحوه اجرا (محلی)

### 1. نصب وابستگی‌ها

```bash
pip install -r requirements.txt
````

### 2. تنظیم متغیرهای محیطی

(فایل `.env` در ریشه پروژه)

```env
GROQ_API_KEY=your_groq_api_key_here
```

### 3. اعمال migrate و اجرای سرور

```bash
python manage.py migrate
python manage.py runserver
```

### 4. دسترسی

* صفحه اصلی: [http://127.0.0.1:8000](http://127.0.0.1:8000)
* پنل مدیریت: [http://127.0.0.1:8000/admin](http://127.0.0.1:8000/admin)

---

## نحوه اجرا با Docker

### 1. ساخت و اجرای کانتینر

```bash
docker-compose up --build
```

### 2. دسترسی به برنامه

```
http://localhost:8000
```

---

## استفاده از LangChain

* از `InMemoryVectorStore` برای ذخیره برداری اسناد استفاده شده است.
* اسناد به چانک‌های 1200 کاراکتری با همپوشانی 300 کاراکتر تقسیم می‌شوند.
* Embedding با مدل `paraphrase-multilingual-MiniLM-L12-v2` انجام می‌شود.
* بازیابی با `similarity_search` و تولید پاسخ با `Groq / Llama-3.1-8b` انجام می‌شود.

---

## داده‌های نمونه

پروژه شامل داده‌های نمونه زیر است:

* **سند ۱**: «مواد مغذی» — مقاله‌ای جامع درباره درشت‌مغذی‌ها و ریز‌مغذی‌ها
* **سند ۲**: «هوش مصنوعی» — مقدمه‌ای بر تاریخچه و شاخه‌های هوش مصنوعی
* **سند ۳**: «رنسانس» — مقدمه‌ای بر دوران رسنانس

### پرسش‌های نمونه

* «پردازش زبان طبیعی چیست؟»
* «اسیدهای چرب ضروری کدامند؟»
* «هوش مصنوعی عمومی چیست؟»
